"""
Task Agent LLM í•¸ë“¤ëŸ¬ v4
ê³µí†µ ëª¨ë“ˆì˜ llm_utilsë¥¼ í™œìš©í•˜ì—¬ LLM ì²˜ë¦¬
"""

import sys
import os
import json
import logging
from typing import Dict, Any, Optional, List

# ê³µí†µ ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), "../shared_modules"))

from llm_utils import get_llm_manager, LLMManager
from env_config import get_config

from models import PersonaType
from config import config
from prompts import prompt_manager

logger = logging.getLogger(__name__)

class TaskAgentLLMHandler:
    """Task Agent ì „ìš© LLM í•¸ë“¤ëŸ¬"""

    def __init__(self):
        """LLM í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”"""
        # ê³µí†µ LLM ë§¤ë‹ˆì € ì‚¬ìš©
        self.llm_manager = get_llm_manager()
        
        # Task Agent ì „ìš© ì„¤ì •
        self.default_provider = "openai"
        
        logger.info(f"Task Agent LLM í•¸ë“¤ëŸ¬ ì´ˆê¸°í™” ì™„ë£Œ (ê¸°ë³¸ í”„ë¡œë°”ì´ë”: {self.default_provider})")

    from typing import Union

    async def analyze_intent(self, message: str, persona: Union[str, PersonaType], 
                       conversation_history: List[Dict] = None) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì˜ë„ ë¶„ì„"""
        try:
            # íˆìŠ¤í† ë¦¬ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            history_context = self._format_history(conversation_history) if conversation_history else ""
            
            # personaë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            persona_str = persona.value if hasattr(persona, 'value') else str(persona)
            
            # ì§ì ‘ LangChainìœ¼ë¡œ LLM í˜¸ì¶œ
            from langchain_openai import ChatOpenAI
            from langchain_core.messages import SystemMessage, HumanMessage
            from langchain_core.output_parsers import JsonOutputParser
            from shared_modules.env_config import get_config
            
            config = get_config()
            
            # ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            llm = ChatOpenAI(
                model="gpt-4o-mini",
                temperature=0.1,
                api_key=config.OPENAI_API_KEY
            )
            
            # JSON íŒŒì„œ ì„¤ì •
            json_parser = JsonOutputParser()
            
            # ë©”ì‹œì§€ êµ¬ì„±
            messages = [
                SystemMessage(content=prompt_manager.get_intent_analysis_prompt()),
                HumanMessage(content=f"""
                í˜ë¥´ì†Œë‚˜: {persona_str}
                ëŒ€í™” íˆìŠ¤í† ë¦¬: {history_context}
                í˜„ì¬ ë©”ì‹œì§€: {message}
                """)
            ]
            
            # ì²´ì¸ êµ¬ì„± ë° ì‹¤í–‰
            chain = llm | json_parser
            result = await chain.ainvoke(messages)
            
            # ê²°ê³¼ ê²€ì¦ ë° ê¸°ë³¸ê°’ ì„¤ì •
            if isinstance(result, dict):
                return {
                    "intent": result.get("intent", "general_inquiry"),
                    "urgency": result.get("urgency", "medium"),
                    "confidence": result.get("confidence", 0.5)
                }
            
            # JSON íŒŒì‹± ì‹œë„ (ê²°ê³¼ê°€ ë¬¸ìì—´ì¸ ê²½ìš°)
            try:
                parsed_result = json.loads(str(result))
                return {
                    "intent": parsed_result.get("intent", "general_inquiry"),
                    "urgency": parsed_result.get("urgency", "medium"),
                    "confidence": parsed_result.get("confidence", 0.5)
                }
            except json.JSONDecodeError:
                pass

        except Exception as e:
            logger.error(f"ì˜ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")

        return self._fallback_intent_analysis(message)

    async def classify_automation_intent(self, message: str) -> Optional[str]:
        """ìë™í™” ì˜ë„ ë¶„ë¥˜"""
        try:
            messages = [
                {"role": "system", "content": prompt_manager.get_automation_classification_prompt()},
                {"role": "user", "content": f"ë©”ì‹œì§€: {message}"}
            ]

            result = await self.llm_manager.generate_response(
                messages=messages,
                provider=self.default_provider,
                output_format="string"
            )
            
            if isinstance(result, str):
                result = result.strip().strip('"')
                return result if result != "none" else None
            
            return None

        except Exception as e:
            logger.error(f"ìë™í™” ì˜ë„ ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
            return None
    async def generate_response(self, message: str, persona: PersonaType, intent: str,
                                context: str = "", conversation_history: List[Dict] = None) -> str:
        """ê°œì¸í™”ëœ ì‘ë‹µ ìƒì„±"""
        try:
            # 1. íˆìŠ¤í† ë¦¬ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            history_context = self._format_history(conversation_history) if conversation_history else ""

            # 2. ì‚¬ìš©ì ì…ë ¥ + íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ ë©”ì‹œì§€ êµ¬ì„±
            context_message = f"{history_context}\n\nì‚¬ìš©ì ë©”ì‹œì§€: {message}".strip()

            # 3. system í”„ë¡¬í”„íŠ¸: í˜ë¥´ì†Œë‚˜+ì˜ë„ ì—­í•  ì§€ì‹œ í”„ë¡¬í”„íŠ¸ë§Œ ì‚¬ìš©
            def is_brief_request(message: str) -> bool:
                return any(kw in message for kw in ["ê°„ë‹¨íˆ", "ìš”ì•½", "ì§§ê²Œ", "í•œëˆˆì—", "í•µì‹¬ë§Œ"])

            def is_detailed_request(message: str) -> bool:
                return any(kw in message for kw in ["ìì„¸íˆ", "ìƒì„¸íˆ", "ì˜ˆì‹œ í¬í•¨", "ì„¤ëª… ì¢€", "ê¸¸ê²Œ"])
            
            system_prompt = prompt_manager.get_intent_specific_prompt(persona, intent)

            if is_brief_request(message):
                system_prompt += "\n\n(ì£¼ì˜: ì‘ë‹µì€ 300ì ì´ë‚´ë¡œ í•µì‹¬ ìš”ì•½. ì´ ë¬¸ì¥ì€ ì¶œë ¥í•˜ì§€ ë§ ê²ƒ.)"
            elif is_detailed_request(message):
                system_prompt += "\n\n(ì£¼ì˜: ê°€ëŠ¥í•œ í•œ êµ¬ì²´ì  ì˜ˆì‹œì™€ í•¨ê»˜ ìƒì„¸í•˜ê²Œ ì„¤ëª…. ì´ ë¬¸ì¥ì€ ì¶œë ¥í•˜ì§€ ë§ ê²ƒ.)"
            else:
                system_prompt += "\n\n(ì£¼ì˜: ê¸°ë³¸ì€ ê°„ê²°í•˜ê²Œ, ì§ˆë¬¸ìê°€ ìš”ì²­ ì‹œì—ë§Œ ìì„¸íˆ ì„¤ëª…. ì´ ë¬¸ì¥ì€ ì¶œë ¥í•˜ì§€ ë§ ê²ƒ.)"
            
            # 6. ê°€ë…ì„± í–¥ìƒìš© ì¶œë ¥ í¬ë§· ì§€ì‹œ ì¶”ê°€
            formatting_instruction = """(ì£¼ì˜: ì•„ë˜ ì§€ì¹¨ì„ ë°˜ì˜í•˜ë˜, ì´ ë¬¸ì¥ì€ ì¶œë ¥í•˜ì§€ ë§ ê²ƒ)

            ì‘ë‹µ í˜•ì‹ ê°€ì´ë“œ:
            - ê° í•­ëª©ì€ í•œ ë¬¸ë‹¨ ì•ˆì— ì‘ì„±
            - ë¶ˆí•„ìš”í•œ ì¤„ë°”ê¿ˆ ì—†ì´, **êµµì€ í‚¤ì›Œë“œ: ì„¤ëª…** í˜•ì‹ìœ¼ë¡œ ì •ë¦¬
            - ì´ëª¨ì§€ë‚˜ ë§ˆí¬ë‹¤ìš´ì€ ê°€ë…ì„± í–¥ìƒì„ ìœ„í•´ ì ì ˆíˆ í™œìš©
            - í•­ëª© ê°„ì—ëŠ” í•œ ì¤„ ì •ë„ ê³µë°±ë§Œ ì‚¬ìš© (ì¤„ë°”ê¿ˆ ë‚¨ìš© X)
            """

            # ğŸ‘‰ system_prompt ìµœì¢… ì¡°í•©
            system_prompt = f"{system_prompt}\n\n{formatting_instruction}"

            # 4. ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ê°€ ìˆë‹¤ë©´ user ë©”ì‹œì§€ì— í¬í•¨
            if context:
                context_message += f"\n\n=== ì¶”ê°€ ì •ë³´ ===\n{context}"

            # 5. êµ¬ì„±ëœ ë©”ì‹œì§€
            messages = [
                {"role": "system", "content": system_prompt.strip()},
                {"role": "user", "content": context_message.strip()}
            ]

            result = await self.llm_manager.generate_response(
                messages=messages,
                provider=self.default_provider,
                output_format="string"
            )

            return str(result) if result else self._fallback_response(persona)

        except Exception as e:
            logger.error(f"ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return self._fallback_response(persona)


    async def extract_information(self, message: str, extraction_type: str, 
                        conversation_history: List[Dict] = None) -> Optional[Dict[str, Any]]:
        """ì •ë³´ ì¶”ì¶œ (ì¼ì •, ì´ë©”ì¼, SNS ë“±) - ë‹¨ì¼/ë‹¤ì¤‘ ì§€ì›"""
        try:
            # íˆìŠ¤í† ë¦¬ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            history_context = self._format_history(conversation_history) if conversation_history else ""
            
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
            system_prompt = prompt_manager.get_information_extraction_prompt(extraction_type)
            
            # ëª…í™•í•œ JSON ì‘ë‹µ ì§€ì‹œ ì¶”ê°€
            enhanced_system_prompt = f"""{system_prompt}

    ì¤‘ìš”: ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
    ì •ë³´ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ì¶”ì¶œí•  ìˆ˜ ì—†ëŠ” ê²½ìš° nullì„ ë°˜í™˜í•˜ì„¸ìš”."""
            
            # ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„± (system_prompt ì¤‘ë³µ ì œê±°)
            user_content = f"""
            ëŒ€í™” íˆìŠ¤í† ë¦¬: {history_context}
            í˜„ì¬ ë©”ì‹œì§€: {message}
            í˜„ì¬ ì‹œê°„: {self._get_current_time()}

            ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {extraction_type} ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
            """
            
            # OpenAI API ì§ì ‘ í˜¸ì¶œ
            import openai
            from shared_modules.env_config import get_config
            
            config = get_config()
            
            # API í‚¤ í™•ì¸
            if not config.OPENAI_API_KEY:
                logger.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return None
                
            client = openai.AsyncOpenAI(api_key=config.OPENAI_API_KEY)
            
            response = await client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": enhanced_system_prompt},
                    {"role": "user", "content": user_content.strip()}
                ],
                temperature=0.1,
                max_tokens=1000,
                response_format={"type": "json_object"}  # JSON ì‘ë‹µ ê°•ì œ
            )
            
            # ì‘ë‹µ ê²€ì¦
            if not response or not response.choices:
                logger.error("OpenAI API ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                return None
                
            if not response.choices[0] or not response.choices[0].message:
                logger.error("OpenAI API ì‘ë‹µ êµ¬ì¡°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return None
                
            result_content = response.choices[0].message.content
            
            # contentê°€ Noneì¸ ê²½ìš° ì²˜ë¦¬
            if result_content is None:
                logger.error("OpenAI APIì—ì„œ contentê°€ Noneì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")
                return None
                
            # ë¹ˆ ë¬¸ìì—´ ì²˜ë¦¬
            if not result_content.strip():
                logger.error("OpenAI APIì—ì„œ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")
                return None
            
            # JSON íŒŒì‹±
            try:
                import json
                parsed_result = json.loads(result_content)
                return parsed_result
                # ê²€ì¦
                # if self._validate_multiple_extraction(parsed_result, extraction_type):
                #     return parsed_result
                # else:
                #     logger.warning(f"ì¶”ì¶œëœ ì •ë³´ê°€ ê²€ì¦ì„ í†µê³¼í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {parsed_result}")
                #     return None
                    
            except json.JSONDecodeError as json_error:
                logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {json_error}, ì‘ë‹µ: {result_content}")
                return None
            
        except openai.APIError as api_error:
            logger.error(f"OpenAI API ì˜¤ë¥˜: {api_error}")
            return None
        except openai.RateLimitError as rate_error:
            logger.error(f"OpenAI API ìš”ì²­ í•œë„ ì´ˆê³¼: {rate_error}")
            return None
        except Exception as e:
            logger.error(f"ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨ ({extraction_type}): {e}")
            return None

    def _validate_multiple_extraction(self, data: Dict[str, Any], extraction_type: str) -> bool:
        """ë‹¤ì¤‘ ì¶”ì¶œëœ ì •ë³´ ê²€ì¦"""
        if extraction_type == "schedule":
            schedules = data.get("schedules", [])
            if not isinstance(schedules, list) or not schedules:
                return False
            # ê° ì¼ì •ì´ í•„ìˆ˜ í•„ë“œë¥¼ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸
            return all(schedule.get("title") and schedule.get("start_time") for schedule in schedules)
        elif extraction_type == "email":
            emails = data.get("emails", [])
            if not isinstance(emails, list) or not emails:
                return False
            return all(email.get("to_emails") and email.get("subject") and email.get("body") for email in emails)
        elif extraction_type == "sns":
            posts = data.get("posts", [])
            if not isinstance(posts, list) or not posts:
                return False
            return all(post.get("platform") and post.get("content") for post in posts)
        return True

    def _format_history(self, conversation_history: List[Dict]) -> str:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬ë§·íŒ…"""
        if not conversation_history:
            return ""
        
        formatted = []
        for msg in conversation_history[-5:]:  # ìµœê·¼ 5ê°œë§Œ
            role = "ì‚¬ìš©ì" if msg["role"] == "user" else "ì—ì´ì „íŠ¸"
            formatted.append(f"{role}: {msg['content']}")
        
        return "\n".join(formatted)

    def _validate_extraction(self, data: Dict[str, Any], extraction_type: str) -> bool:
        """ì¶”ì¶œëœ ì •ë³´ ê²€ì¦"""
        if extraction_type == "schedule":
            return bool(data.get("title") and data.get("start_time"))
        elif extraction_type == "email":
            return bool(data.get("to_emails") and data.get("subject") and data.get("body"))
        elif extraction_type == "sns":
            return bool(data.get("platform") and data.get("content"))
        return True

    def _get_current_time(self) -> str:
        """í˜„ì¬ ì‹œê°„ ë°˜í™˜"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    def _fallback_intent_analysis(self, message: str) -> Dict[str, Any]:
        """ë°±ì—… ì˜ë„ ë¶„ì„"""
        message_lower = message.lower()
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„
        if any(word in message_lower for word in ["ìë™í™”", "ìë™", "ì˜ˆì•½", "ìŠ¤ì¼€ì¤„"]):
            intent = "task_automation"
        elif any(word in message_lower for word in ["ì¼ì •", "ë¯¸íŒ…", "íšŒì˜"]):
            intent = "schedule_management"
        elif any(word in message_lower for word in ["ë„êµ¬", "í”„ë¡œê·¸ë¨", "ì¶”ì²œ"]):
            intent = "tool_recommendation"
        else:
            intent = "general_inquiry"

        urgency = "high" if any(word in message_lower for word in ["ê¸´ê¸‰", "ì¦‰ì‹œ", "ì§€ê¸ˆ"]) else "medium"

        return {
            "intent": intent,
            "urgency": urgency,
            "confidence": 0.3
        }

    def _fallback_response(self, persona) -> str:
        """ë°±ì—… ì‘ë‹µ"""
        # personaë¥¼ ì•ˆì „í•˜ê²Œ ë¬¸ìì—´ë¡œ ë³€í™˜
        persona_str = persona.value if hasattr(persona, 'value') else str(persona)
        return f"{persona_str}ë¥¼ ìœ„í•œ ë§ì¶¤ ì¡°ì–¸ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ì£¼ì‹œë©´ ë” ì •í™•í•œ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."

    def get_status(self) -> Dict[str, Any]:
        """LLM í•¸ë“¤ëŸ¬ ìƒíƒœ ë°˜í™˜"""
        llm_status = self.llm_manager.get_status()
        
        return {
            "task_agent_handler": {
                "default_provider": self.default_provider,
                "initialized": True
            },
            "llm_manager_status": llm_status
        }

    def test_connection(self) -> Dict[str, bool]:
        """LLM ì—°ê²° í…ŒìŠ¤íŠ¸"""
        return self.llm_manager.test_connection()

